
1. 如何降低采集服务对业务集群的影响？
业务集群的节点上只部署agent，改agent只负责数据的采集，不负责数据的处理。数据的处理由另外的数据处理集群来负责。

2. 如何调度任务使负载均衡。
agent模式，所有的任务都是运行在agent上。agent负责数据的拉取，数据解析成metrics格式，上报metrics数据。也可以引入在agent集群调度任务
worker模式，存在scheduler组件，根据worker的资源使用在worker集群中调度任务。

3. 是否支持横向扩容
agent模式，一般使用daemonset模式，无法支持横向扩容
worker模式，数据处理的任务都是在worker集群运行，可以横向扩容worker集群。

4. 如何处理异常
tail push模式 按时间维度清洗日志。以一分钟为例，数据接收队列需要缓存数据，至少要到下一分钟的数据到来 才能处理这一分钟的数据。
队列需要保证在任何情况下 数据不丢失。即使队列存在节点异常。因为tail模式 agent发送数据成功后 不会再次发送数据
如果worker节点异常 也可以重新调度任务

pull模式 worker集群定时任务 采集一分钟的数据完成，开始处理数据。
如果此分钟任务失败，记录，任务调度到其它节点 重新经由agent获取数据 计算。即使worker节点异常 也可以重新从agent拉取数据。

5. 如何保证日志顺序
push模式 依赖于kafka来保证日志时间顺序
pull模式 一个日志只会在一个进程定时拉取，该进程能够保证日志的时间顺序。微批处理

6. 日志滚动导致同一分钟数据分布在两个日志
tail模式 并发tail时 当日志滚动时 debug.log debug.log.1 debug.log的起始日志可能不是分钟的起始时间 需要等到debug.log.1 tail完毕之后才能处理debug.log中起始几行的数据。
解决办法 支持日志滚动 顺序tail
pull模式 如果支持多个文件的并发pull 也会存在这个问题。同理可以通过串行pull来解决。同时需要处理pull到日志结尾时 需要获取新的日志文件的数据，直到时间超过一分钟。

7. 如何保证日志不堆积
监控，存在异常及时处理。
tail模式由于只能存在一个进程消费日志 无法快速消费。
pull模式可以通过把日志采集分成几个大的时间段(为了减少频繁的查找日志offset 尽快可以用二分查找 但是由于多次IO 也是比较慢的)，并发采集同一个日志文件。
例如一天的日志 可以分为24个时间段，24个并发进程同时采集。只要IO不是瓶颈就可以。

8. 需要测试tail模式和pull模式的性能

9. 如何支持指定时间段的任务采集
pull模式本身就是按照时间段采集的 天生支持
tail模式由于是tail 那么需要修改tail逻辑支持按照时间来tail。即起始通过时间找到日志offset，然后tail，直到tail到终止时间点

10. pull的架构更简单，因为push模式需要引入kafka

11. tail的速率快还是日志写入的速率快？

12. tail的IO次数多 还是 pull批量日志的IO次数多

13. tail模式每一行日志都需要attach tags，消耗agent cpu。pull模式不需要 因为是批量拉取日志。当然可以修改tail的逻辑 支持批量，tag的处理在清洗集群

14. 监控服务的性质，能不引入依赖尽量不要引入依赖。架构越简单越好，监控是需要稳定性最高的服务。稳定性级别最好。
另外监控服务不是日志服务，获取日志是为了从日志中提取要监控的数据，而非日志存储。不是日志服务

15. 监控服务和日志服务是否要合并。
从稳定性的角度来看 不要合并
从功能的角度来看 可以合并。监控可以依赖于日志服务。但是监控的目的是为了保障其它服务的稳定性。依赖于日志服务不太好

16. 采集的集群方案不论pull模式还是push模式都是一样的？

17. pull可以是同一个节点的数据位于一个worker上，单机维度数据计算效率较高。至于热点的问题，可以通过调度其它任务到其它worker上来解决。
主题思想是经过多级聚合计算来完成数据的聚合计算。worker可以加速单机粒度数据的计算，至于多机间的聚合计算交给二级计算任务来做。比如spark

如果采集不需要支持单机粒度的聚合计算，那么完全可以均衡调度任务，及同一个节点的任务不一定需要在同一个work中。计算完全交由spark做

18. 内部监控系统和公有云监控系统的区别。
公有云监控系统主要提供数据的存储和计算，无法在采集侧优化。同时只能使用push模式
内部监控系统可以使用pull模式 在采集侧优化 减小架构复杂 提升稳定性。
同时就算是公有云监控，实际上采集的稳定性和数据质量是交给客户自己owner。
客户需要自己解决采集任务的调度，由于公有云监控不得不提供类似kafka(push)，所以客户来说直接push最简单。实际上复杂性在监控server。
就算在公有云模式，采集任务已daemonset模式也是不合适的。
  1. 业务集群资源有限，agent无法分配过多资源
  2. agent资源限制，日志采集会成为瓶颈
  3. 为了调度任务，采集集群仍是需要的：
    scheduler 调度采集任务
    controller 管理采集任务的状态
    master
  针对采集集群来说 增加一个worker角色不算多复杂。同时减少了agent的变更频率。很多功能的开发都是在worker来支持 而不是在agent来支持。
  比如prometheus metrics数据，如果一个exporter的数据量有1G 那么agent很可能直接就oom，但是worker节点可以申请大规格容器来支持。daemonset无法大规格 业务集群资源有限 影响业务
  
  但是就算针对公有云，让客户安装一个简单的agent也比安装复杂的filebeat强。agent简单 故障少 bug少。复杂的逻辑都在worker 容易排查问题和升级(支持新的功能，客户agent升级也是一个很麻烦的事情)
  唯一需要做的一个事情就是worker集群需要每一个节点都能够被公网访问，应为agent需要与worker建连。同时也需要加强worker的安全和鉴权
  
  此时的问题是 server侧需要的资源更多了，用户需要的费用也就更多了。因为之前agent侧的计算从客户转嫁到了server。实际上是一个价格的转嫁。因为就算在客户侧客户也是需要提供资源来支持采集的


监控数据分两部分 
一是和稳定性相关的关键数据
二是一些业务的关键数据
三是客户自己的数据

主要的是一 二部分的数据，通过pull来拉取。可以支持push 但是不保证数据质量 或者如何保证数据质量
push相对于pull来说 对整个监控系统来说 更复杂写 引入了kafka

另外如果要支持前置计算：
1. 是通过一个独立的spark集群 调用数据库里面的数据 计算完之后 写入新的数据到数据库
2. 是数据在写入(push)数据库之前路由到spark集群 spark集群接收数据计算。这个是否也会引入kafka还是spark集群能够接收数据
针对push模式 本身就有kafka 无非是计算出一份新的数据再次写入kafka 这个模式怎么支持不保留明细数据 只保留聚合后的数据
针对pull模式 kafka从数据库或者计算侧来拉取数据 同时把拉取到的数据和新计算得到的数据 写入到数据库

spark聚合数据的话 如果聚合的时间比较长 比如一天 也是需要从数据库查询数据的。kafka会保留一天的数据么 应该不会。消费掉就删掉了。

针对公有云 一般是小场景 daemonset agent也就够了。不需要复杂的采集
针对公司内部 才会有大量数据的采集 才会有上面一套系统的架构

在引入前置计算的模式下，push和pull哪个更好？
push 到 spark spark计算 写入数据库
push 到 kafka spark从kafka消费 写入数据库。
push的话 采集侧不需要有存储的能力。
pull模式 本地存储 spark 从采集侧直接拉取数据 如果需要长时间的数据 需要再次从DB拉取数据 或者直接从DB拉取数据
pull模式 如果没有 前置计算的话 需要支持 push数据到DB 这个也不需要本地存储 只需要处理push失败的数据存储就行

prometheus是如何支持前置计算的 也就是 record rule能力？

采集同时支持pull和push pull的模式下 本地存储 保存一天。采集集群 类似于prometheus构成集群 同时增加了scheduler和controller的能力。
也不对，采集主要是做数据的采集和清洗 不做数据的计算

pull接口 是按照数据采集到的时间维度来 分批拉取的。定时拉取 只拉取最近采集到的 一分钟或者一秒钟的数据。这个时间是采集的时间 而非数据的时间
push的话 就简单了 采集到数据直接push就可以了。


监控开源 不应该考虑公有云 而应该考虑内部的方案。

直接push会减小采集侧的复杂度。

数据产生方 应该和 数据使用方 分开来。数据产生方提供数据 数据使用方使用数据。

采集
计算
存储
