
worker 承载任务的处理，数据的解析。通过插件的方式

1. 资源数据的解析
2. http数据的解析。比如prometheus协议的数据
3. tcp数据的解析。
4. 日志解析。从日志中获取metrics信息
5. command命令结果数据解析

微批处理（获取、解析）数据。

上述几种数据，无论何种采集都是拉取数据。和社区的区别是一个是没有worker角色，agent直接拉取。一个是有worker角色，worker来拉取。

如果worker只是拉取数据，那么就需要kafka来接收日志数据，worker push数据到kafka。日志清洗集群 清洗日志成metrics，计算集群做metrics的预计算。
如果worker集群负责日志的拉取和清理，好处：微批处理 单机的数据在单个worker上 计算效率高
worker节点的存在可以提高拉取数据的效率 通过横向扩容。但是社区的模式无法通过横向扩容来提高吞吐量。另外filebeat的并发采集也无法保证日志的时间顺序。
而拉取模式可以并发 同时采取一定的策略 可以保证日志的时间顺序。
tail模式 一个日志文件只能由一个进程来处理 读取速度小于写入速度？日志堆积。pull模式 一个日志文件可以由多个进程同时拉取？
pull 如果也是依赖于offset的话，那么一个日志文件也只能由一个进程采集。

如果push模式 那么必须引入kafka，worker节点通过消费kafka的数据 来进行日志清洗。
如果要做计算 怎么消费数据，如何从kafka中消费某一时间段的数据 并做计算处理 如何调度。
kafka如何保证日志的写入顺序：
1. agent可以保证同一个日志文件写入kafka是按照顺序写入的
2. 就算agent保证了顺序写入，kafka集群化 数据分片 是如何保证数据获取是按照时间顺序的

kafka支持限流

如果pull模式，任务调度在某个worker 那么这个worker就负责日志采集和清洗 能够保证日志时间顺序
如果worker失败 任务是可以调度到其它的worker
pull模式 可以支持日志的任意时间点的采集 比如某一段时间的数据丢失了 指定时间段 重新拉取
tail模式 如果某一时间段数据丢失 无法支持特定时间段的数据重新采集
kafka接收的同一个节点的数据 由于分片的原因也可能位于kafka集群不同的节点
worker模式能够通过控制任务调度 来控制同一节点的数据 尽可能的位于同一worker节点。数据热点的问题？

采集 计算分离

